{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_pretrained_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5UuGPtKaR1Jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5986b75d-c274-47bd-8b9b-1b4832e05aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install the necessary libraries"
      ],
      "metadata": {
        "id": "xCAdIVkySkr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VMg0GpZWR_0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd530bc-0385-420e-f499-2e7f79efd1ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import the libraries"
      ],
      "metadata": {
        "id": "lT4ys_xqShZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n"
      ],
      "metadata": {
        "id": "g6xCU8lKR_wf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set the filepath of the model"
      ],
      "metadata": {
        "id": "jsvhbfUpSZpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = 'gdrive/MyDrive/project/model'"
      ],
      "metadata": {
        "id": "LnCZrsBER_t4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load the trained model "
      ],
      "metadata": {
        "id": "XlH_QrF5SVe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading tokenizer from the saved model path\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(save_path)\n",
        "tokenizer.add_special_tokens({\n",
        "  \"eos_token\": \"</s>\",\n",
        "  \"bos_token\": \"<s>\",\n",
        "  \"unk_token\": \"<unk>\",\n",
        "  \"pad_token\": \"<pad>\",\n",
        "  \"mask_token\": \"<mask>\"\n",
        "})\n",
        "\n",
        "# loading pretrained model\n",
        "model = TFGPT2LMHeadModel.from_pretrained(save_path)"
      ],
      "metadata": {
        "id": "rSEnO8N5R_rX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0493c5b-c1d3-4e4a-94d1-8d1f5907f725"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gdrive/MyDrive/project/model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate short stories"
      ],
      "metadata": {
        "id": "GCyIk7bCSOrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Μια φορά και έναν καιρό, \"\n",
        "# encoding the input text\n",
        "input_ids = tokenizer.encode(text, return_tensors='tf')\n",
        "\n",
        "# getting out output\n",
        "beam_output = model.generate(\n",
        "  input_ids,\n",
        "  max_length = 100,\n",
        "  num_beams = 10,\n",
        "  temperature = 0.7,\n",
        "  no_repeat_ngram_size=1,\n",
        "  num_return_sequences=10,\n",
        "  repetition_penalty=1.5,\n",
        "  skip_special_tokens = True,\n",
        "  clean_up_tokenization = True,\n",
        "  early_stopping = True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(beam_output[0]))"
      ],
      "metadata": {
        "id": "R3-gwkwiR_pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8047e338-c9a3-4f89-b144-ec59728fdabe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Μια φορά και έναν καιρό,  σε ένα κουνελάκι που έκανε την πρώτη μέρα ήτανε πολύ έξυπνο. Το κοριτσάκι χτύπησε με ανοιχτό το κεφάλι της στον μπαμπά του: Τι λες; Θέλεις να μου πεις πως είναι έτσι πραγματικά ωραία εδώ μέσα;, ρώτησε η αρκουδίτσα μας!, είπε κάπως πιο όμορφα!Και ζήσαν αυτοί καλά κι εμείς καλύτερα...Η κατσίκα αυτή στην κορυφήτης δεν είχε ακούσει τόσα χρόνια όταν ήρθε μια βραδιάυε καθόλου όμορφη ζωή τους τον κόσμο από τα ποντίκια χωρίς έκαναν παρέα σήμερα μάλιστα κατάλαβαν τι κάνει για τη μαμά\n"
          ]
        }
      ]
    }
  ]
}